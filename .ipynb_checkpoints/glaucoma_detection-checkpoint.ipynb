{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 597,
     "status": "ok",
     "timestamp": 1683123000284,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": 420
    },
    "id": "L8OsbAmhWqP-",
    "outputId": "92ad2682-3338-4ee9-d6a6-698510031caf"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "# print(os.listdir(('/content/drive/MyDrive/GlauPro')))\n",
    "\n",
    "import datetime as datetime\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow import keras\n",
    "import keras.layers as layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import itertools\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(256, 256, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN vanilla_model without regularization\n",
    "vanilla_model = Sequential()\n",
    "vanilla_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "vanilla_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vanilla_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "vanilla_model.add(Dropout(0.25))\n",
    "vanilla_model.add(Flatten())\n",
    "vanilla_model.add(Dense(128, activation='relu'))\n",
    "vanilla_model.add(Dropout(0.5))\n",
    "vanilla_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "vanilla_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "vanilla_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALEXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6892,
     "status": "ok",
     "timestamp": 1683123172079,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": 420
    },
    "id": "eIjxmKzsWqYB",
    "outputId": "acc6f548-2ee2-4a9b-86e6-9ffc438e3677"
   },
   "outputs": [],
   "source": [
    "# AlexNet model\n",
    "class AlexNet(Sequential):\n",
    "    def __init__(self, num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.add(Conv2D(96, kernel_size=(11,11), strides= 4,\n",
    "                        padding= 'valid', activation= 'relu',\n",
    "                         input_shape=input_shape,\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(5,5), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None)) \n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(Conv2D(384, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(Conv2D(256, kernel_size=(3,3), strides= 1,\n",
    "                        padding= 'same', activation= 'relu',\n",
    "                        kernel_initializer= 'he_normal'))\n",
    "\n",
    "        self.add(MaxPooling2D(pool_size=(3,3), strides= (2,2),\n",
    "                              padding= 'valid', data_format= None))\n",
    "\n",
    "        self.add(Flatten())\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dense(4096, activation= 'relu'))\n",
    "        self.add(Dense(1000, activation= 'relu'))\n",
    "        self.add(Dense(num, activation= 'sigmoid'))\n",
    "\n",
    "        #self.compile(loss='binary_crossentropy', optimizer='adamax', metrics=['categorical_accuracy'])\n",
    "        \n",
    "        # opt = SGD(lr=0.01, momentum=0.9)\n",
    "        self.compile(loss='binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "        \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        sublayer_config = config.pop(\"sublayer\")\n",
    "        sublayer = keras.saving.deserialize_keras_object(sublayer_config)\n",
    "        return cls(sublayer, **config)\n",
    "\n",
    "cls = 1\n",
    "alexnet_model = AlexNet(cls)\n",
    "alexnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model Definition\n",
    "def create_googlenet_model(num):\n",
    "    model = Sequential()\n",
    "    inputs = keras.Input(shape=input_shape, name='Input')\n",
    "    x = layers.Conv2D(32, 3, padding='same', kernel_regularizer = regularizers.l2(0.01),\n",
    "                    name='Conv_1')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding='same', kernel_regularizer = regularizers.l2(0.01),\n",
    "                    name='Conv_2')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "\n",
    "    x = layers.Conv2D(128, 3, padding='same', kernel_regularizer = regularizers.l2(0.01), name='Conv_3')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "    x = layers.MaxPooling2D()(x)\n",
    "\n",
    "    x = layers.Conv2D(32, 3, padding='same', kernel_regularizer = regularizers.l2(0.01), name='Conv_4')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = keras.activations.relu(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation='relu', kernel_regularizer = regularizers.l2(0.01))(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output = layers.Dense(num)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=output)\n",
    "    \n",
    "    #opt = SGD(lr=0.01, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "cls = 1\n",
    "googlenet_model = create_googlenet_model(cls)\n",
    "googlenet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "x = res_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "output_layer = Dense(1, activation='sigmoid')(x)  # Binary classification output\n",
    "\n",
    "resnet_model = Model(inputs=res_model.input, outputs=output_layer)\n",
    "\n",
    "#opt = SGD(lr=0.01, momentum=0.9)\n",
    "resnet_model.compile(loss='binary_crossentropy',\n",
    "              optimizer = 'adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "resnet_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5371,
     "status": "ok",
     "timestamp": 1683123185562,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": 420
    },
    "id": "QPmdewLQWqcw",
    "outputId": "b0ca371f-3d08-4ab8-f0b8-ecff077c0d49"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, rotation_range = 20, width_shift_range =0.1, height_shift_range = 0.1,fill_mode='nearest',\n",
    "shear_range = 0.2,\n",
    "zoom_range = 0.2,\n",
    "horizontal_flip = True)\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "train_set = train_datagen.flow_from_directory('dataset/dataset/train',\n",
    "                                              target_size = (256,256),\n",
    "                                              batch_size = 32,\n",
    "                                              class_mode = 'binary')\n",
    "# print(test_datagen)\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/dataset/test',\n",
    "                                            target_size = (256,256),\n",
    "                                            batch_size = 32, \n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_set.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "EPOCH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class timecallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        self.times = []\n",
    "        # use this value as reference to calculate cummulative time taken\n",
    "        self.timetaken = time.process_time()\n",
    "    def on_epoch_end(self,epoch,logs = {}):\n",
    "        self.times.append((epoch,time.process_time() - self.timetaken))\n",
    "    def on_train_end(self,logs = {}):\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Total time taken until an epoch in seconds')\n",
    "        plt.plot(*zip(*self.times))\n",
    "        plt.savefig(str(self.timetaken)+'_time.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(mdl, name):\n",
    "    batch_size = 32\n",
    "    mdl_history = mdl.fit_generator(train_set,\n",
    "                      epochs =EPOCH,\n",
    "                      callbacks=[timecallback()],\n",
    "                      steps_per_epoch = 455/batch_size,\n",
    "                      validation_data = test_set)\n",
    "    mdl.save(name + '.h5')\n",
    "    mdl_pred(mdl)\n",
    "    return mdl_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mdl_pred(mdl):\n",
    "    preds = mdl.predict(test_set)\n",
    "    \n",
    "    scores = mdl.evaluate(test_set)\n",
    "    print(\"%s%s: %.2f%%\" % (\"evaluate \",mdl.metrics_names[1], scores[1]*100))\n",
    "    \n",
    "    #score = mdl.evaluate_generator(test_set,preds)\n",
    "    #print(\" Total: \", len(test_set.filenames))\n",
    "    #print(\"Loss: \", score[0], \"Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_plot(vanilla_history, alex_history, google_history, resnet_history):\n",
    "    plt.subplots_adjust(left=0.01,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.4, \n",
    "                    hspace=0.4)\n",
    "    plt.figure(figsize=(13,6))\n",
    "    plt.tight_layout()\n",
    "    handle = ['Vanilla CNN', 'AlexNet', 'GoogleNet', 'ResNet']\n",
    "    dash = [(5, 1), (5, 5), (5, 10), (5, 15)]\n",
    "    count = 0\n",
    "    for history in [vanilla_history, alex_history, google_history, resnet_history]:\n",
    "        \n",
    "        # Accessing and visualizing training history\n",
    "        print(history.history.keys())\n",
    "        plt.suptitle(\"Loss\")\n",
    "        # Plot training and validation loss\n",
    "     \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['loss'], label = handle[count], linestyle='--', dashes=dash[count])\n",
    "        plt.title('Training Set')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['val_loss'], label = handle[count], linestyle='--', dashes=dash[count])\n",
    "        plt.title('Validation Set')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        count = count+1\n",
    "    plt.savefig('loss.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    plt.figure(figsize=(13,6))\n",
    "    plt.tight_layout()\n",
    "    count = 0\n",
    "    for history in [vanilla_history, alex_history, google_history, resnet_history]:\n",
    "        # Plot training and validation accuracy\n",
    "        \n",
    "        print(history.history.keys())\n",
    "        plt.suptitle(\"Accuracy\")\n",
    "        # Plot training and validation loss\n",
    "     \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(history.history['accuracy'], label = handle[count], linestyle='--', dashes=dash[count])\n",
    "        plt.title('Training Set')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(history.history['val_accuracy'], label = handle[count], linestyle='--', dashes=dash[count])\n",
    "        plt.title('Validation Set')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "        count = count+1\n",
    "    plt.savefig('accuracy.png', dpi=300, bbox_inches='tight', transparent=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_plot(alex_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "vanilla_history = modelling(vanilla_model, 'vanilla_CNN_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "alex_history = modelling(alexnet_model, 'alexnet_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "googlenet_history = modelling(googlenet_model, 'googlenet_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "resnet_history = modelling(resnet_model, 'resnet_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_plot(vanilla_history, alex_history, googlenet_history, resnet_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = ['Not-Glaucoma','Glaucoma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    cb = plt.colorbar()\n",
    "    cb.remove() \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_mtx(model, name):\n",
    "    #Confution Matrix\n",
    "    Y_pred = model.predict_generator(test_set) > 0.5\n",
    "    y_pred = Y_pred\n",
    "    # np.argmax(Y_pred, axis=1)\n",
    "    # [f[0] for f in Y_pred]\n",
    "    print(Y_pred)\n",
    "    print(y_pred)\n",
    "    print('Confusion Matrix')\n",
    "    cm = confusion_matrix(test_set.classes, y_pred)\n",
    "    #disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_list)\n",
    "    #disp.plot()\n",
    "    \n",
    "    sns.heatmap(cm, square=True, annot=True, fmt='d', cbar=False, cmap='Blues',\n",
    "            xticklabels=class_list, yticklabels=class_list)\n",
    " \n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('Actual label')\n",
    "    #plot_confusion_matrix(cm, class_list, title='Confusion Matrix', classes = class_list)\n",
    "    #Print Classification Report\n",
    "    print('Classification Report')\n",
    "    print(classification_report(test_set.classes, y_pred))\n",
    "    plt.savefig(name +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vanilla CNN Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AlexNet Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mtx(vanilla_model, 'vanilla_cnn_cfx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mtx(alexnet_model, 'alexnet_cfx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GoogleNet Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mtx(googlenet_model, 'ggnet_cfx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ResNet Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_mtx(resnet_model, 'resnet_cfx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4614,
     "status": "ok",
     "timestamp": 1679741834798,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": -60
    },
    "id": "5HLo3AcCZ3Pt",
    "outputId": "2974b92f-9616-4ab7-8d1e-066b2b79ff63"
   },
   "outputs": [],
   "source": [
    "\n",
    "model=load_model('alexnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 935,
     "status": "ok",
     "timestamp": 1679741838314,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": -60
    },
    "id": "tBYT79eYWq_2",
    "outputId": "f6651754-2a0c-4f04-fda4-ac0037003241"
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('/content/drive/MyDrive/GlauPro/dataset/dataset/test/class1/Im256.jpg', target_size = (256,256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "train_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "     print(\"Glaucoma\")\n",
    "else:\n",
    "     print(\"Not Glaucoma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 530,
     "status": "ok",
     "timestamp": 1679741842829,
     "user": {
      "displayName": "Ise ayo",
      "userId": "04666722418098736313"
     },
     "user_tz": -60
    },
    "id": "YJ54sOruaOsX",
    "outputId": "70a61918-7e1d-4277-e552-468dc93a0906"
   },
   "outputs": [],
   "source": [
    "test_image = image.load_img('/content/drive/MyDrive/GlauPro/dataset/dataset/test/class0/Im001.jpg', target_size = (256,256))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "train_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "     print(\"Glaucoma\")\n",
    "else:\n",
    "     print(\"Not Glaucoma\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w7pBk6UWquK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsarXoRFWqra"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9KcZ2hNWqnn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vWEnNna4Wqhw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cu8fL8dMWqgQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
